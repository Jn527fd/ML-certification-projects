# -*- coding: utf-8 -*-
"""Copy of fcc_book_recommendation_knn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D0Hn_9F8xkn8zXqmAuvDqg0kYkLJc3Us
"""

# import libraries (you may add additional imports but you may not have to)
import numpy as np
import pandas as pd
from scipy.sparse import csr_matrix
from sklearn.neighbors import NearestNeighbors
import matplotlib.pyplot as plt

# get data files
!wget https://cdn.freecodecamp.org/project-data/books/book-crossings.zip

!unzip book-crossings.zip

books_filename = 'BX-Books.csv'
ratings_filename = 'BX-Book-Ratings.csv'

# import csv data into dataframes
df_books = pd.read_csv(
    books_filename,
    encoding = "ISO-8859-1",
    sep=";",
    header=0,
    names=['isbn', 'title', 'author'],
    usecols=['isbn', 'title', 'author'],
    dtype={'isbn': 'str', 'title': 'str', 'author': 'str'})

df_ratings = pd.read_csv(
    ratings_filename,
    encoding = "ISO-8859-1",
    sep=";",
    header=0,
    names=['user', 'isbn', 'rating'],
    usecols=['user', 'isbn', 'rating'],
    dtype={'user': 'int32', 'isbn': 'str', 'rating': 'float32'})

# add your code here - consider creating a new cell for each section of code
df_ratings

# noAuthor = pd.isnull(df_books['author'])
# df_books_with_Authors = df_books.dropna(axis=0,subset=['author'])

# Filter active users with at least 200 ratings
user_counts = df_ratings.groupby('user')['rating'].count()
active_users = df_ratings[df_ratings['user'].isin(user_counts.index[user_counts >= 200])]

# Filter popular books with at least 100 ratings
isbn_counts = df_ratings.groupby('isbn')['rating'].count()
dfbooks = df_ratings[df_ratings['isbn'].isin(isbn_counts.index[isbn_counts >= 100])]

# dfbooks=popular_books.merge(df_books_with_Authors, left_on='isbn', right_on='isbn')[['user', 'isbn', 'rating', 'title', 'author']]
# dfbooks.head()

dfbooks.drop_duplicates(subset='isbn',keep='first').shape

df_merge=pd.merge(dfbooks, active_users, how='inner', indicator=False)
df_merge.drop_duplicates(subset='user',keep='first').shape, df_merge.drop_duplicates(subset='isbn',keep='first').shape

df_unique=df_merge.drop_duplicates(['title','user'])

pivot_books= df_unique.pivot(index='title',columns='user', values='rating').fillna(0)
pivot_books

KNN = NearestNeighbors(algorithm='brute', metric='cosine')
KNN.fit(pivot_books.values)

# function to return recommended books - this will be tested
def get_recommends(book = ""):
  distance, indices = KNN.kneighbors(pivot_books.loc[book].values.reshape(1,-1), n_neighbors=6)
  nearest_book=pivot_books.iloc[indices[0]].index.values
  #make list of books and distance
  result=list(zip(nearest_book,distance[0]))
  result[0]=result[0][0] #to erase the distance=0 from the given book
  result.reverse()
  recommended_books=result[-1:]+[result[:-1]]
  return recommended_books

books = get_recommends("Where the Heart Is (Oprah's Book Club (Paperback))")
print(books)

def test_book_recommendation():
  test_pass = True
  recommends = get_recommends("Where the Heart Is (Oprah's Book Club (Paperback))")
  if recommends[0] != "Where the Heart Is (Oprah's Book Club (Paperback))":
    test_pass = False
  recommended_books = ["I'll Be Seeing You", 'The Weight of Water', 'The Surgeon', 'I Know This Much Is True']
  recommended_books_dist = [0.8, 0.77, 0.77, 0.77]
  for i in range(2):
    if recommends[1][i][0] not in recommended_books:
      test_pass = False
    if abs(recommends[1][i][1] - recommended_books_dist[i]) >= 0.05:
      test_pass = False
  if test_pass:
    print("You passed the challenge! ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰")
  else:
    print("You haven't passed yet. Keep trying!")

test_book_recommendation()